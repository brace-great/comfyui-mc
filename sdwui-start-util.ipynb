{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import subprocess\n",
    "import threading\n",
    "import sys\n",
    "import socket\n",
    "import torch\n",
    "from typing import List\n",
    "import uuid\n",
    "import asyncio\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 内置参数默认值，当上下文有参数时可覆盖默认值\n",
    "_runing = False\n",
    "autoPackPendingZip = (\n",
    "    locals().get(\"autoPackPendingZip\") or globals().get(\"autoPackPendingZip\") or False\n",
    ")\n",
    "monitorDownloadList = (\n",
    "    locals().get(\"monitorDownloadList\") or globals().get(\"monitorDownloadList\") or False\n",
    ")\n",
    "autoUnzipInput = (\n",
    "    locals().get(\"autoUnzipInput\") or globals().get(\"autoUnzipInput\") or False\n",
    ")\n",
    "# zrok 支持（终极稳定版）\n",
    "useZrok = locals().get(\"useZrok\") or globals().get(\"useZrok\") or False\n",
    "zrok_token = locals().get(\"zrok_token\") or globals().get(\"zrok_token\") or \"\"\n",
    "\n",
    "_useFrpc = locals().get('useFrpc') or globals().get('useFrpc') or True\n",
    "\n",
    "_useNgrok = locals().get('useNgrok') or globals().get('useNgrok') or True\n",
    "\n",
    "_reLoad = locals().get('reLoad') or globals().get('reLoad') or False\n",
    "    \n",
    "_before_downloading = locals().get('before_downloading') or globals().get('before_downloading') or ''\n",
    "\n",
    "_async_downloading = locals().get('async_downloading') or globals().get('async_downloading') or ''\n",
    "\n",
    "_before_start_sync_downloading = locals().get('before_start_sync_downloading') or globals().get('before_start_sync_downloading') or  ''\n",
    "\n",
    "_server_port = locals().get('server_port') or globals().get('server_port') or 7860\n",
    "    \n",
    "_sd_git_repo = locals().get('sd_git_repo') or globals().get('sd_git_repo') or 'https://github.com/viyiviyi/stable-diffusion-webui.git -b local' \n",
    "_sd_git_repo = _sd_git_repo\\\n",
    "    .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "    .replace('{wui}',\"webui\")\n",
    "    \n",
    "_sd_config_git_repu = locals().get('sd_config_git_repu') or globals().get('sd_config_git_repu') or 'https://github.com/viyiviyi/sd-configs.git'\n",
    "_sd_config_git_repu = _sd_config_git_repu\\\n",
    "    .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "    .replace('{wui}',\"webui\")\n",
    "    \n",
    "    \n",
    "_huggingface_token = locals().get('huggingface_token') or globals().get('huggingface_token') or '{input_path}/configs/huggingface_token.txt'\n",
    "_huggingface_token = _huggingface_token\\\n",
    "    .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "    .replace('{wui}',\"webui\")\n",
    "    \n",
    "_huggingface_repo = locals().get('huggingface_repo') or globals().get('huggingface_repo') or ''\n",
    "_huggingface_repo = _huggingface_repo\\\n",
    "    .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "    .replace('{wui}',\"webui\")\n",
    "\n",
    "_link_instead_of_copy = locals().get('link_instead_of_copy') or globals().get('link_instead_of_copy') or True\n",
    "    \n",
    "show_shell_info = locals().get('hidden_console_info') or globals().get('hidden_console_info')\n",
    "if show_shell_info is None: show_shell_info = False\n",
    "else: show_shell_info = not show_shell_info\n",
    "\n",
    "_multi_case = locals().get('multi_case') or globals().get('multi_case') or False\n",
    "    \n",
    "_skip_start = locals().get('skip_start') or globals().get('skip_start') or True\n",
    "\n",
    "def before_start():\n",
    "    pass\n",
    "\n",
    "def main_start():\n",
    "    pass\n",
    "\n",
    "_on_before_start = locals().get('on_before_start') or globals().get('on_before_start') or before_start \n",
    "_skip_webui = locals().get('skip_webui') or globals().get('skip_webui') or False\n",
    "    \n",
    "run_by_none_device = False\n",
    "\n",
    "_proxy_path = locals().get('proxy_path') or globals().get('proxy_path') or {}\n",
    "\n",
    "_sub_path =  locals().get('sub_path') or globals().get('sub_path') or ['/','/1/']\n",
    "if len(_sub_path) != 2:\n",
    "    _sub_path = ['/','/1/']\n",
    "    \n",
    "_config_args:dict[str, str] =  locals().get('config_args') or globals().get('config_args') or {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run(command, cwd=None, desc=None, errdesc=None, custom_env=None,try_error:bool=True) -> str:\n",
    "    global show_shell_info\n",
    "    if desc is not None:\n",
    "        print(desc)\n",
    "\n",
    "    run_kwargs = {\n",
    "        \"args\": command,\n",
    "        \"shell\": True,\n",
    "        \"cwd\": cwd,\n",
    "        \"env\": os.environ if custom_env is None else custom_env,\n",
    "        \"encoding\": 'utf8',\n",
    "        \"errors\": 'ignore',\n",
    "    }\n",
    "\n",
    "    if not show_shell_info:\n",
    "        run_kwargs[\"stdout\"] = run_kwargs[\"stderr\"] = subprocess.PIPE\n",
    "\n",
    "    result = subprocess.run(**run_kwargs)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        error_bits = [\n",
    "            f\"{errdesc or 'Error running command'}.\",\n",
    "            f\"Command: {command}\",\n",
    "            f\"Error code: {result.returncode}\",\n",
    "        ]\n",
    "        if result.stdout:\n",
    "            error_bits.append(f\"stdout: {result.stdout}\")\n",
    "        if result.stderr:\n",
    "            error_bits.append(f\"stderr: {result.stderr}\")\n",
    "        if try_error:\n",
    "            print((RuntimeError(\"\\n\".join(error_bits))))\n",
    "        else:\n",
    "            raise RuntimeError(\"\\n\".join(error_bits))\n",
    "\n",
    "    if show_shell_info:\n",
    "        print((result.stdout or \"\"))\n",
    "    return (result.stdout or \"\")\n",
    "\n",
    "def mkdirs(path, exist_ok=True):\n",
    "    if path and not Path(path).exists():\n",
    "        os.makedirs(path,exist_ok=exist_ok)\n",
    "\n",
    "\n",
    "# 检查网络\n",
    "def check_service(host, port):\n",
    "    try:\n",
    "        socket.create_connection((host, port), timeout=5)\n",
    "        return True\n",
    "    except socket.error:\n",
    "        return False\n",
    "\n",
    "\n",
    "# 检查gpu是否存在\n",
    "def check_gpu():\n",
    "    if not run_by_none_device and torch.cuda.device_count() == 0:\n",
    "        raise Exception('当前环境没有GPU')\n",
    "\n",
    "\n",
    "def echoToFile(content:str,path:str):\n",
    "    if path.find('/') >= 0:\n",
    "        _path = '/'.join(path.split('/')[:-1])\n",
    "        run(f'''mkdir -p {_path}''')\n",
    "    with open(path,'w') as sh:\n",
    "        sh.write(content)\n",
    "        \n",
    "def get_freefrp_confog(local_port):\n",
    "    rd_str = uuid.uuid1()\n",
    "    return (f'''\n",
    "[common]\n",
    "server_addr = frp.freefrp.net\n",
    "server_port = 7000\n",
    "token = freefrp.net\n",
    "\n",
    "[{rd_str}_http]\n",
    "type = http\n",
    "local_ip = 127.0.0.1\n",
    "local_port = {local_port}\n",
    "custom_domains = {rd_str}.frp.eaias.com\n",
    "''',f'http://{rd_str}.frp.eaias.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "_install_path = f\"/kaggle\" if os.path.exists('/kaggle/') else f\"{os.environ['HOME']}/sd_webui\" # 安装目录\n",
    "_output_path = '/kaggle/working' if os.path.exists('/kaggle/working/') else f\"{os.environ['HOME']}/.sdwui/Output\" # 输出目录 如果使用google云盘 会在google云盘增加sdwebui/Output\n",
    "_input_path = '/kaggle/input' # 输入目录\n",
    "_ui_dir_name = 'sd_main_dir'\n",
    "\n",
    "_install_path = locals().get('install_path') or globals().get('install_path') or _install_path\n",
    "_output_path = locals().get('output_path') or globals().get('output_path') or _output_path\n",
    "_input_path = locals().get('input_path') or globals().get('input_path') or _input_path\n",
    "_ui_dir_name = locals().get('ui_dir_name') or globals().get('ui_dir_name') or _ui_dir_name\n",
    "\n",
    "install_path = _install_path\n",
    "output_path = _output_path\n",
    "input_path = _input_path\n",
    "ui_dir_name = _ui_dir_name\n",
    "    \n",
    "google_drive = '' \n",
    "\n",
    "\n",
    "_useGooglrDrive = locals().get('useGooglrDrive') or globals().get('useGooglrDrive') or True\n",
    "\n",
    "# 连接谷歌云\n",
    "try:\n",
    "    if _useGooglrDrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount(f'~/google_drive')\n",
    "        google_drive = f\"{os.environ['HOME']}/google_drive/MyDrive\"\n",
    "        _output_path = f'{google_drive}/sdwebui/Output'\n",
    "        _input_path = f'{google_drive}/sdwebui/Input'\n",
    "        run(f'''mkdir -p {_input_path}''')\n",
    "        print('''\n",
    "已经链接到谷歌云盘\n",
    "已在云盘创建Input和Output目录\n",
    "        ''')\n",
    "except:\n",
    "    _useGooglrDrive = False\n",
    "\n",
    "run(f'''mkdir -p {_install_path}''')\n",
    "run(f'''mkdir -p {_output_path}''')\n",
    "\n",
    "\n",
    "os.environ['install_path'] = _install_path\n",
    "os.environ['output_path'] = _output_path\n",
    "os.environ['google_drive'] = google_drive\n",
    "os.environ['input_path'] = _input_path\n",
    "\n",
    "def replace_path(input_str:str):\n",
    "    if not input_str: return ''\n",
    "    for key in _config_args:\n",
    "        input_str = input_str.replace(key,_config_args[key])\n",
    "        \n",
    "    if not (locals().get('use_comfyui') or globals().get('use_comfyui') or False):\n",
    "        input_str = input_str.replace('https://github.com/comfyanonymous/ComfyUI.git','https://github.com/comfyanonymous/ComfyUI.git')\n",
    "        \n",
    "    return input_str.replace('$install_path',_install_path)\\\n",
    "    .replace('{install_path}',_install_path)\\\n",
    "    .replace('$input_path',_input_path)\\\n",
    "    .replace('{input_path}',_input_path)\\\n",
    "    .replace('$output_path',_output_path)\\\n",
    "    .replace('{output_path}',_output_path)\\\n",
    "    .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "    .replace('{wui}',\"webui\")\n",
    "\n",
    "space_string = ' \\n\\r\\t\\'\\\",'\n",
    "\n",
    "def config_reader(conf:str):\n",
    "    conf = conf or \"\"\n",
    "    args = [replace_path(item.split('#')[0].strip(space_string)) for item in conf.split('\\n') if item.strip(space_string)]\n",
    "    return [item.strip() for item in args if item.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "i3LhnwYHLCtC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ngrokTokenFile = os.path.join(_input_path,'configs/ngrok_token.txt') # 非必填 存放ngrokToken的文件的路径\n",
    "frpcConfigFile = os.path.join(_input_path,'configs/frpc_koishi.ini') # 非必填 frp 配置文件\n",
    "# ss证书目录 下载nginx的版本，把pem格式改成crt格式\n",
    "frpcSSLFFlies = [os.path.join(_input_path,'configs/koishi_ssl')]\n",
    "if 'frp_ssl_dir' in locals() or 'frp_ssl_dir' in globals():\n",
    "    frpcSSLFFlies = frpcSSLFFlies + config_reader(locals().get('frp_ssl_dir') or globals().get('frp_ssl_dir'))\n",
    "# frpc 文件目录 如果目录不存在，会自动下载，也可以在数据集搜索 viyiviyi/utils 添加\n",
    "frpcExePath = os.path.join(_input_path,'utils-tools/frpc')\n",
    "# 其他需要加载的webui启动参数 写到【参数列表】这个配置去\n",
    "otherArgs = '--xformers'\n",
    "if 'sd_start_args' in locals() or 'sd_start_args' in globals():\n",
    "    otherArgs = ' '.join([item for item in config_reader(locals().get('sd_start_args') or globals().get('sd_start_args')) if item != '--no-gradio-queue'])\n",
    "venvPath = os.path.join(_input_path,'sd-webui-venv/venv.tar.bak') # 安装好的python环境 sd-webui-venv是一个公开是数据集 可以搜索添加\n",
    "\n",
    "# 用于使用kaggle api的token文件 参考 https://www.kaggle.com/docs/api\n",
    "# 此文件用于自动上传koishi的相关配置 也可以用于保存重要的输出文件\n",
    "kaggleApiTokenFile = os.path.join(_input_path,'configs/kaggle.json')\n",
    "\n",
    "requirements = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "a_GtG2ayLCtD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 这下面的是用于初始化一些值或者环境变量的，轻易别改\n",
    "_setting_file = replace_path(locals().get('setting_file') or globals().get('setting_file') or 'config.json')\n",
    "\n",
    "_ui_config_file = replace_path(locals().get('ui_config_file') or globals().get('ui_config_file') or 'ui-config.json')\n",
    "\n",
    "# 设置文件路径\n",
    "if Path(f\"{os.environ['HOME']}/google_drive/MyDrive\").exists():\n",
    "    if _setting_file == '/kaggle/working/configs/config.json':\n",
    "        _setting_file = os.path.join(_output_path,'configs/config.json')\n",
    "    if _ui_config_file == '/kaggle/working/configs/ui-config.json':\n",
    "        _ui_config_file = os.path.join(_output_path,'configs/ui-config.json')\n",
    "    \n",
    "frpcStartArg = ''\n",
    "freefrp_url = ''\n",
    "_frp_temp_config_file = ''\n",
    "_frp_config_or_file = replace_path(locals().get('frp_config_or_file') or globals().get('frp_config_or_file')) or frpcConfigFile\n",
    "run(f'''mkdir -p {_install_path}/configFiles''')\n",
    "if _frp_config_or_file:\n",
    "    if '[common]' in _frp_config_or_file:\n",
    "        echoToFile(_frp_config_or_file,f'{_install_path}/configFiles/temp_frpc_webui.ini')\n",
    "        _frp_temp_config_file = f'{_install_path}/configFiles/temp_frpc_webui.ini'\n",
    "    elif '.ini' in _frp_config_or_file:\n",
    "        _frp_temp_config_file = _frp_config_or_file.strip()\n",
    "        \n",
    "    if _frp_temp_config_file:\n",
    "        if Path(_frp_temp_config_file).exists():\n",
    "            run(f'''cp -f {_frp_temp_config_file} {_install_path}/configFiles/frpc_webui.ini''')\n",
    "            run(f'''sed -i \"s/local_port = .*/local_port = {_server_port}/g\" {_install_path}/configFiles/frpc_webui.ini''')\n",
    "            frpcStartArg = f' -c {_install_path}/configFiles/frpc_webui.ini'\n",
    "    elif _frp_config_or_file.strip().startswith('-f'):\n",
    "        frpcStartArg = _frp_config_or_file.strip()\n",
    "        \n",
    "if not frpcStartArg and _useFrpc:\n",
    "    conf,url = get_freefrp_confog(_server_port)\n",
    "    echoToFile(conf,f'{_install_path}/configFiles/frpc_webui.ini')\n",
    "    freefrp_url = url\n",
    "    frpcStartArg = f' -c {_install_path}/configFiles/frpc_webui.ini'\n",
    "\n",
    "ngrokToken=''\n",
    "_ngrok_config_or_file = replace_path(locals().get('ngrok_config_or_file') or globals().get('ngrok_config_or_file')) or ngrokTokenFile\n",
    "if _ngrok_config_or_file:\n",
    "    if Path(_ngrok_config_or_file.strip()).exists():\n",
    "        ngrokTokenFile = _ngrok_config_or_file.strip()\n",
    "    if Path(ngrokTokenFile).exists():\n",
    "        with open(ngrokTokenFile,encoding = \"utf-8\") as nkfile:\n",
    "            ngrokToken = nkfile.readline()\n",
    "    elif not _ngrok_config_or_file.strip().startswith('/'):\n",
    "        ngrokToken=_ngrok_config_or_file.strip()\n",
    "    \n",
    "if not Path(venvPath).exists():\n",
    "    venvPath = os.path.join(_input_path,'sd-webui-venv/venv.zip')\n",
    "    \n",
    "huggingface_headers:dict = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_conf():\n",
    "    global _useFrpc\n",
    "    global _useNgrok\n",
    "    global _reLoad\n",
    "    global _before_downloading\n",
    "    global _async_downloading\n",
    "    global _before_start_sync_downloading\n",
    "    global _server_port\n",
    "    global _sd_git_repo\n",
    "    global _sd_config_git_repu\n",
    "    global _huggingface_token\n",
    "    global _huggingface_repo\n",
    "    global _link_instead_of_copy\n",
    "    global show_shell_info\n",
    "    global _multi_case\n",
    "    global _skip_start\n",
    "    global _on_before_start\n",
    "    global _skip_webui\n",
    "    global _proxy_path\n",
    "    global _sub_path\n",
    "    global _config_args\n",
    "    global _install_path\n",
    "    global _output_path\n",
    "    global _input_path\n",
    "    global _ui_dir_name\n",
    "    \n",
    "    global ngrokTokenFile\n",
    "    global frpcConfigFile\n",
    "    global frpcSSLFFlies\n",
    "    global frpcExePath\n",
    "    global otherArgs\n",
    "    global _setting_file\n",
    "    global _ui_config_file\n",
    "    global _frp_temp_config_file\n",
    "    global _frp_config_or_file\n",
    "    global ngrokToken\n",
    "    global venvPath\n",
    "    \n",
    "    _useFrpc = locals().get('useFrpc') or globals().get('useFrpc') or True\n",
    "    _useNgrok = locals().get('useNgrok') or globals().get('useNgrok') or True\n",
    "    _reLoad = locals().get('reLoad') or globals().get('reLoad') or False\n",
    "    _before_downloading = locals().get('before_downloading') or globals().get('before_downloading') or ''\n",
    "    _async_downloading = locals().get('async_downloading') or globals().get('async_downloading') or ''\n",
    "    _before_start_sync_downloading = locals().get('before_start_sync_downloading') or globals().get('before_start_sync_downloading') or  ''\n",
    "    _server_port = locals().get('server_port') or globals().get('server_port') or 7860\n",
    "    _sd_git_repo = locals().get('sd_git_repo') or globals().get('sd_git_repo') or 'https://github.com/viyiviyi/stable-diffusion-webui.git -b local' \n",
    "    _sd_git_repo = _sd_git_repo\\\n",
    "        .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "        .replace('{wui}',\"webui\")  \n",
    "    _sd_config_git_repu = locals().get('sd_config_git_repu') or globals().get('sd_config_git_repu') or 'https://github.com/viyiviyi/sd-configs.git'\n",
    "    _sd_config_git_repu = _sd_config_git_repu\\\n",
    "        .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "        .replace('{wui}',\"webui\")\n",
    "    _huggingface_token = locals().get('huggingface_token') or globals().get('huggingface_token') or '{input_path}/configs/huggingface_token.txt'\n",
    "    _huggingface_token = _huggingface_token\\\n",
    "        .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "        .replace('{wui}',\"webui\")\n",
    "    _huggingface_repo = locals().get('huggingface_repo') or globals().get('huggingface_repo') or ''\n",
    "    _huggingface_repo = _huggingface_repo\\\n",
    "        .replace('{sdwui}','stable-diffusion-webui')\\\n",
    "        .replace('{wui}',\"webui\")\n",
    "    _link_instead_of_copy = locals().get('link_instead_of_copy') or globals().get('link_instead_of_copy') or True\n",
    "    show_shell_info = locals().get('hidden_console_info') or globals().get('hidden_console_info')\n",
    "    if show_shell_info is None: show_shell_info = False\n",
    "    else: show_shell_info = not show_shell_info\n",
    "    _multi_case = locals().get('multi_case') or globals().get('multi_case') or False\n",
    "    _skip_start = locals().get('skip_start') or globals().get('skip_start') or True\n",
    "    _on_before_start = locals().get('on_before_start') or globals().get('on_before_start') or before_start \n",
    "    _skip_webui = locals().get('skip_webui') or globals().get('skip_webui') or False\n",
    "    _proxy_path = locals().get('proxy_path') or globals().get('proxy_path') or {}\n",
    "    _sub_path =  locals().get('sub_path') or globals().get('sub_path') or ['/','/1/']\n",
    "    if len(_sub_path) != 2:\n",
    "        _sub_path = ['/','/1/']\n",
    "        \n",
    "    _config_args =  locals().get('config_args') or globals().get('config_args') or {}\n",
    "    \n",
    "    _install_path = locals().get('install_path') or globals().get('install_path') or _install_path\n",
    "    _output_path = locals().get('output_path') or globals().get('output_path') or _output_path\n",
    "    _input_path = locals().get('input_path') or globals().get('input_path') or _input_path\n",
    "    _ui_dir_name = locals().get('ui_dir_name') or globals().get('ui_dir_name') or _ui_dir_name\n",
    "    \n",
    "    ngrokTokenFile = os.path.join(_input_path,'configs/ngrok_token.txt') # 非必填 存放ngrokToken的文件的路径\n",
    "    frpcConfigFile = os.path.join(_input_path,'configs/frpc_koishi.ini') # 非必填 frp 配置文件\n",
    "    # ss证书目录 下载nginx的版本，把pem格式改成crt格式\n",
    "    frpcSSLFFlies = [os.path.join(_input_path,'configs/koishi_ssl')]\n",
    "    if 'frp_ssl_dir' in locals() or 'frp_ssl_dir' in globals():\n",
    "        frpcSSLFFlies = frpcSSLFFlies + config_reader(locals().get('frp_ssl_dir') or globals().get('frp_ssl_dir'))\n",
    "    # frpc 文件目录 如果目录不存在，会自动下载，也可以在数据集搜索 viyiviyi/utils 添加\n",
    "    frpcExePath = os.path.join(_input_path,'utils-tools/frpc')\n",
    "    # 其他需要加载的webui启动参数 写到【参数列表】这个配置去\n",
    "    otherArgs = '--xformers'\n",
    "    if 'sd_start_args' in locals() or 'sd_start_args' in globals():\n",
    "        otherArgs = ' '.join([item for item in config_reader(locals().get('sd_start_args') or globals().get('sd_start_args')) if item != '--no-gradio-queue'])\n",
    "\n",
    "    # 这下面的是用于初始化一些值或者环境变量的，轻易别改\n",
    "    _setting_file = replace_path(locals().get('setting_file') or globals().get('setting_file') or 'config.json')\n",
    "\n",
    "    _ui_config_file = replace_path(locals().get('ui_config_file') or globals().get('ui_config_file') or 'ui-config.json')\n",
    "\n",
    "    # 设置文件路径\n",
    "    if Path(f\"{os.environ['HOME']}/google_drive/MyDrive\").exists():\n",
    "        if _setting_file == '/kaggle/working/configs/config.json':\n",
    "            _setting_file = os.path.join(_output_path,'configs/config.json')\n",
    "        if _ui_config_file == '/kaggle/working/configs/ui-config.json':\n",
    "            _ui_config_file = os.path.join(_output_path,'configs/ui-config.json')\n",
    "        \n",
    "    frpcStartArg = ''\n",
    "    freefrp_url = ''\n",
    "    _frp_temp_config_file = ''\n",
    "    _frp_config_or_file = replace_path(locals().get('frp_config_or_file') or globals().get('frp_config_or_file')) or frpcConfigFile\n",
    "    run(f'''mkdir -p {_install_path}/configFiles''')\n",
    "    if _frp_config_or_file:\n",
    "        if '[common]' in _frp_config_or_file:\n",
    "            echoToFile(_frp_config_or_file,f'{_install_path}/configFiles/temp_frpc_webui.ini')\n",
    "            _frp_temp_config_file = f'{_install_path}/configFiles/temp_frpc_webui.ini'\n",
    "        elif '.ini' in _frp_config_or_file:\n",
    "            _frp_temp_config_file = _frp_config_or_file.strip()\n",
    "            \n",
    "        if _frp_temp_config_file:\n",
    "            if Path(_frp_temp_config_file).exists():\n",
    "                run(f'''cp -f {_frp_temp_config_file} {_install_path}/configFiles/frpc_webui.ini''')\n",
    "                run(f'''sed -i \"s/local_port = .*/local_port = {_server_port}/g\" {_install_path}/configFiles/frpc_webui.ini''')\n",
    "                frpcStartArg = f' -c {_install_path}/configFiles/frpc_webui.ini'\n",
    "        elif _frp_config_or_file.strip().startswith('-f'):\n",
    "            frpcStartArg = _frp_config_or_file.strip()\n",
    "            \n",
    "    if not frpcStartArg and _useFrpc:\n",
    "        conf,url = get_freefrp_confog(_server_port)\n",
    "        echoToFile(conf,f'{_install_path}/configFiles/frpc_webui.ini')\n",
    "        freefrp_url = url\n",
    "        frpcStartArg = f' -c {_install_path}/configFiles/frpc_webui.ini'\n",
    "\n",
    "    ngrokToken=''\n",
    "    _ngrok_config_or_file = replace_path(locals().get('ngrok_config_or_file') or globals().get('ngrok_config_or_file')) or ngrokTokenFile\n",
    "    if _ngrok_config_or_file:\n",
    "        if Path(_ngrok_config_or_file.strip()).exists():\n",
    "            ngrokTokenFile = _ngrok_config_or_file.strip()\n",
    "        if Path(ngrokTokenFile).exists():\n",
    "            with open(ngrokTokenFile,encoding = \"utf-8\") as nkfile:\n",
    "                ngrokToken = nkfile.readline()\n",
    "        elif not _ngrok_config_or_file.strip().startswith('/'):\n",
    "            ngrokToken=_ngrok_config_or_file.strip()\n",
    "        \n",
    "    if not Path(venvPath).exists():\n",
    "        venvPath = os.path.join(_input_path,'sd-webui-venv/venv.zip')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件下载工具\n",
    "\n",
    "---\n",
    "\n",
    "link_or_download_flie(config:str, skip_url:bool=False, _link_instead_of_copy:bool=True, base_path:str = '',sync:bool=False,thread_num:int=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import importlib\n",
    "import os\n",
    "import pprint\n",
    "import re\n",
    "import venv\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import requests\n",
    "\n",
    "show_shell_info = False\n",
    "\n",
    "def is_installed(package):\n",
    "    try:\n",
    "        spec = importlib.util.find_spec(package)\n",
    "    except ModuleNotFoundError:\n",
    "        return False\n",
    "\n",
    "    return spec is not None\n",
    "\n",
    "def download_file(url:str, filename:str, dist_path:str, cache_path = '',_link_instead_of_copy:bool=True,headers={}):\n",
    "    startTicks = time.time()\n",
    "    # 获取文件的真实文件名\n",
    "    if not filename:\n",
    "        with requests.get(url, stream=True,headers=headers) as r:\n",
    "            if 'Content-Disposition' in r.headers:\n",
    "                filename = r.headers['Content-Disposition'].split('filename=')[1].strip('\"')\n",
    "            r.close()\n",
    "    if not filename and re.search(r'/[^/]+\\.[^/]+$',url):\n",
    "        filename = url.split('/')[-1].split('?')[0]\n",
    "    \n",
    "    filename = re.sub(r'[\\\\/:*?\"<>|;]', '', filename)\n",
    "    filename = re.sub(r'[\\s\\t]+', '_', filename)\n",
    "    \n",
    "    print(f'下载 {filename} url: {url} --> {dist_path}')\n",
    "    \n",
    "    # 创建目录\n",
    "    if cache_path and not Path(cache_path).exists():\n",
    "        os.makedirs(cache_path,exist_ok=True)\n",
    "    if dist_path and not Path(dist_path).exists():\n",
    "        os.makedirs(dist_path,exist_ok=True)\n",
    "        \n",
    "    # 拼接文件的完整路径\n",
    "    filepath = os.path.join(dist_path, filename)\n",
    "\n",
    "    if cache_path:\n",
    "        cache_path = os.path.join(cache_path, filename)\n",
    "        \n",
    "    # 判断文件是否已存在\n",
    "    if Path(filepath).exists():\n",
    "        print(f'文件 {filename} 已存在 {dist_path}')\n",
    "        return\n",
    "    \n",
    "    if cache_path and Path(cache_path).exists():\n",
    "        run(f'cp -n -r -f {\"-s\" if _link_instead_of_copy else \"\"} {cache_path} {dist_path}')\n",
    "        print(f'文件缓存 {cache_path} --> {dist_path}')\n",
    "        return\n",
    "    # 下载文件\n",
    "    size = 0\n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(cache_path or filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
    "                if chunk:\n",
    "                    size += len(chunk)\n",
    "                    f.write(chunk)\n",
    "    # 如果使用了缓存目录 需要复制或链接文件到目标目录\n",
    "    if cache_path:\n",
    "        run(f'cp -n -r -f {\"-s\" if _link_instead_of_copy else \"\"} {cache_path} {dist_path}')\n",
    "    ticks = time.time()\n",
    "    print(f'下载完成 {filename} --> {dist_path} 大小{round(size/1024/1024,2)}M 耗时:{round(ticks - startTicks,2)}秒')\n",
    "        \n",
    "def download_git(url, dist_path, cache_path = '',_link_instead_of_copy:bool=True):\n",
    "    if not Path(dist_path).exists():\n",
    "        os.makedirs(dist_path,exist_ok=True)\n",
    "    if show_shell_info:\n",
    "        print(f'git 下载 {url} --> {dist_path}')\n",
    "    if cache_path and not Path(cache_path).exists():\n",
    "        os.makedirs(cache_path,exist_ok=True)\n",
    "        run(f'git clone {url}',cwd = cache_path)\n",
    "    if cache_path:\n",
    "        run(f'cp -n -r -f {cache_path}/* {dist_path}')\n",
    "    else:\n",
    "        run(f'git clone {url}',cwd = dist_path)\n",
    "    if show_shell_info:\n",
    "        print(f'git 下载完成 {url} --> {dist_path}')\n",
    "    \n",
    "    \n",
    "def download_huggingface(url:str, filename:str, dist_path, cache_path = '',_link_instead_of_copy:bool=True):\n",
    "    fileReg = r'^https:\\/\\/huggingface.co(\\/([^\\/]+\\/)?[^\\/]+\\/[^\\/]+\\/(resolve|blob)\\/[^\\/]+\\/|[^\\.]+\\.[^\\.]+$|download=true)'\n",
    "    def isFile(url:str):\n",
    "        if re.match(fileReg,url):\n",
    "            return True\n",
    "        return False\n",
    "    if isFile(url):\n",
    "        download_file(url,filename,dist_path,cache_path,_link_instead_of_copy,headers=huggingface_headers)\n",
    "    else:\n",
    "        download_git(url,dist_path,cache_path,_link_instead_of_copy)\n",
    "    \n",
    "# 加入文件到下载列表\n",
    "def pause_url(url:str,dist_path:str):\n",
    "    file_name = ''\n",
    "    if re.match(r'^[^:]+:(https?|ftps?)://', url, flags=0):\n",
    "        file_name = re.findall(r'^[^:]+:',url)[0][:-1]\n",
    "        url = url[len(file_name)+1:]\n",
    "    if not re.match(r'^(https?|ftps?)://',url):\n",
    "        return\n",
    "    file_name = re.sub(r'\\s+','_',file_name or '')\n",
    "    path_hash = str(hash(url)).replace('-','')\n",
    "    \n",
    "    return {'file_name':file_name,'path_hash':path_hash,'url':url,'dist_path':dist_path}\n",
    "\n",
    "def download_urls(download_list:List[dict],sync:bool=False,thread_num:int=5, \n",
    "                  cache_path:str=os.path.join(os.environ['HOME'],'.cache','download_util'),\n",
    "                  _link_instead_of_copy:bool=True,is_await:bool=False):\n",
    "    if sync:\n",
    "        for conf in download_list:\n",
    "            cache_dir = os.path.join(cache_path,conf['path_hash'])\n",
    "            if conf['url'].startswith('https://github.com'):\n",
    "                try:\n",
    "                    download_git(conf['url'],conf['dist_path'],cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy)\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "            if conf['url'].startswith('https://huggingface.co'):\n",
    "                try:\n",
    "                    download_huggingface(conf['url'],conf['file_name'],conf['dist_path'],cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy)\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "            if conf['url'].startswith('https://civitai.com'):\n",
    "                if not re.search(r'token=.+', conf['url']):\n",
    "                    if conf['url'].find('?') == -1:\n",
    "                        conf['url'] = conf['url']+'?token=fee8bb78b75566eddfd04d061996185c'\n",
    "                    else:\n",
    "                        conf['url'] = conf['url']+'&token=fee8bb78b75566eddfd04d061996185c'\n",
    "            try:\n",
    "                download_file(conf['url'],conf['file_name'],conf['dist_path'],cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        executor = concurrent.futures.ThreadPoolExecutor(max_workers=thread_num)\n",
    "        futures = []\n",
    "        for conf in download_list:\n",
    "            cache_dir = os.path.join(cache_path,conf['path_hash'])\n",
    "            if conf['url'].startswith('https://github.com'):\n",
    "                futures.append(executor.submit(download_git, conf['url'],conf['dist_path'],\n",
    "                                                cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy))\n",
    "                continue\n",
    "            if conf['url'].startswith('https://huggingface.co'):\n",
    "                futures.append(executor.submit(download_huggingface,conf['url'],conf['file_name'],conf['dist_path'],cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy))\n",
    "                continue\n",
    "            if conf['url'].startswith('https://civitai.com'):\n",
    "                if not re.search(r'token=.+', conf['url']):\n",
    "                    if conf['url'].find('?') == -1:\n",
    "                        conf['url'] = conf['url']+'?token=fee8bb78b75566eddfd04d061996185c'\n",
    "                    else:\n",
    "                        conf['url'] = conf['url']+'&token=fee8bb78b75566eddfd04d061996185c'\n",
    "            futures.append(executor.submit(download_file, conf['url'],conf['file_name'],conf['dist_path'],\n",
    "                                            cache_path=cache_dir,_link_instead_of_copy=_link_instead_of_copy))\n",
    "        if is_await:\n",
    "            concurrent.futures.wait(futures)\n",
    "            \n",
    "                          \n",
    "def parse_config(config:str):\n",
    "    space_string = ' \\n\\r\\t\\'\\\",'\n",
    "    other_flie_list = [item.split('#')[0].strip(space_string) for item in config.split('\\n') if item.strip(space_string)]\n",
    "    other_flie_list = [item.strip() for item in other_flie_list if item.strip()]\n",
    "    other_flie_list_store = {}\n",
    "    other_flie_list_store_name='default'\n",
    "    other_flie_list_store_list_cache=[]\n",
    "    \n",
    "    for item in other_flie_list:\n",
    "        if item.startswith('[') and item.endswith(']'):\n",
    "            if not other_flie_list_store_name == 'default':\n",
    "                other_flie_list_store[other_flie_list_store_name]=other_flie_list_store_list_cache\n",
    "                other_flie_list_store_list_cache = []\n",
    "            other_flie_list_store_name = item[1:-1]\n",
    "        else:\n",
    "            other_flie_list_store_list_cache.append(item)\n",
    "    other_flie_list_store[other_flie_list_store_name]=other_flie_list_store_list_cache\n",
    "    \n",
    "    return other_flie_list_store\n",
    "\n",
    "\n",
    "def link_or_download_flie(config:str, skip_url:bool=False, _link_instead_of_copy:bool=True, base_path:str = '',\n",
    "                          sync:bool=False,thread_num:int=None, is_await:bool=False):\n",
    "    store:dict[str,List[str]] = parse_config(config)\n",
    "    download_list = []\n",
    "    for dist_dir in store.keys():\n",
    "        dist_path = os.path.join(base_path,dist_dir)\n",
    "        os.makedirs(dist_path,exist_ok=True)\n",
    "        for path in store[dist_dir]:\n",
    "            if 'https://' in path or 'http://' in path:\n",
    "                if skip_url:\n",
    "                    continue\n",
    "                if sync:\n",
    "                    try:\n",
    "                        download_urls([pause_url(path,dist_path)],_link_instead_of_copy = _link_instead_of_copy, sync=sync)\n",
    "                    except:\n",
    "                        pass\n",
    "                    continue\n",
    "                download_list.append(pause_url(path,dist_path))\n",
    "            else:\n",
    "                run(f'cp -n -r -f {\"-s\" if _link_instead_of_copy else \"\"} {path} {dist_path}')\n",
    "                if show_shell_info:\n",
    "                    print(f'{\"链接\" if _link_instead_of_copy else \"复制\"} {path} --> {dist_path}')\n",
    "        run(f'rm -f {dist_path}/\\*.* ')\n",
    "    if not skip_url:\n",
    "        if show_shell_info:\n",
    "            pprint.pprint(download_list)\n",
    "        try:\n",
    "            download_urls(download_list,_link_instead_of_copy = _link_instead_of_copy, sync=sync, thread_num=thread_num or 3,is_await=is_await)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0uS-BLULCtD"
   },
   "source": [
    "## kaggle public API\n",
    "\n",
    "**不能使用%cd这种会改变当前工作目录的命令，会导致和其他线程冲突**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "m8FJi4j0LCtD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 安装kaggle的api token文件\n",
    "def initKaggleConfig():\n",
    "    if Path('~/.kaggle/kaggle.json').exists():\n",
    "        return True\n",
    "    if Path(kaggleApiTokenFile).exists():\n",
    "        run(f'''mkdir -p ~/.kaggle/''')\n",
    "        run('cp '+kaggleApiTokenFile+' ~/.kaggle/kaggle.json')\n",
    "        run(f'''chmod 600 ~/.kaggle/kaggle.json''')\n",
    "        return True\n",
    "    print('缺少kaggle的apiToken文件，访问：https://www.kaggle.com/你的kaggle用户名/account 获取')\n",
    "    return False\n",
    "\n",
    "def getUserName():\n",
    "    if not initKaggleConfig(): return\n",
    "    import kaggle\n",
    "    return kaggle.KaggleApi().read_config_file()['username']\n",
    "\n",
    "def createOrUpdateDataSet(path:str,datasetName:str):\n",
    "    if not initKaggleConfig(): return\n",
    "    print('创建或更新数据集 '+datasetName)\n",
    "    import kaggle\n",
    "    run(f'mkdir -p {_install_path}/kaggle_cache')\n",
    "    run(f'rm -rf {_install_path}/kaggle_cache/*')\n",
    "    datasetDirPath = _install_path+'/kaggle_cache/'+datasetName\n",
    "    run('mkdir -p '+datasetDirPath)\n",
    "    run('cp -f '+path+' '+datasetDirPath+'/')\n",
    "    username = getUserName()\n",
    "    print(\"kaggle username:\"+username)\n",
    "    datasetPath = username+'/'+datasetName\n",
    "    datasetList = kaggle.api.dataset_list(mine=True,search=datasetPath)\n",
    "    print(datasetList)\n",
    "    if len(datasetList) == 0 or datasetPath not in [str(d) for d in datasetList]: # 创建 create\n",
    "        run('kaggle datasets init -p' + datasetDirPath)\n",
    "        metadataFile = datasetDirPath+'/dataset-metadata.json'\n",
    "        run('sed -i s/INSERT_TITLE_HERE/'+ datasetName + '/g ' + metadataFile)\n",
    "        run('sed -i s/INSERT_SLUG_HERE/'+ datasetName + '/g ' + metadataFile)\n",
    "        run('cat '+metadataFile)\n",
    "        run('kaggle datasets create -p '+datasetDirPath)\n",
    "        print('create database done')\n",
    "    else:\n",
    "        kaggle.api.dataset_metadata(datasetPath,datasetDirPath)\n",
    "        kaggle.api.dataset_create_version(datasetDirPath, 'auto update',dir_mode='zip')\n",
    "        print('upload database done')\n",
    "\n",
    "def downloadDatasetFiles(datasetName:str,outputPath:str):\n",
    "    if not initKaggleConfig(): return\n",
    "    print('下载数据集文件 '+datasetName)\n",
    "    import kaggle\n",
    "    username = getUserName()\n",
    "    datasetPath = username+'/'+datasetName\n",
    "    datasetList = kaggle.api.dataset_list(mine=True,search=datasetPath)\n",
    "    if datasetPath not in [str(d) for d in datasetList]:\n",
    "        return False\n",
    "    run('mkdir -p '+outputPath)\n",
    "    kaggle.api.dataset_download_files(datasetPath,path=outputPath,unzip=True)\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同步文件夹到 huggingface\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 文件夹与 huggingface 同步\n",
    "if _huggingface_token and _huggingface_repo:\n",
    "    if not is_installed('watchdog'):\n",
    "        requirements.append('watchdog')\n",
    "    if not is_installed('huggingface_hub'):\n",
    "        requirements.append('huggingface_hub')\n",
    "    else:\n",
    "        try:\n",
    "            from huggingface_hub  import HfApi,login,snapshot_download\n",
    "        except:\n",
    "            requirements.append('huggingface_hub')\n",
    "\n",
    "huggingface_is_init = False\n",
    "\n",
    "def init_huggingface():\n",
    "    if not _huggingface_token:\n",
    "        return False\n",
    "\n",
    "    global huggingface_headers\n",
    "    global huggingface_is_init\n",
    "    \n",
    "    from huggingface_hub  import login\n",
    "    token = replace_path(_huggingface_token)\n",
    "    if not _huggingface_token.startswith('hf_') and Path(token).exists():\n",
    "        with open(token,encoding = \"utf-8\") as nkfile:\n",
    "            token = nkfile.readline()\n",
    "    if not token.startswith('hf_'):\n",
    "        print('huggingface token 不正确，请将 token 或 仅存放token 的txt文件路径填入 _huggingface_token 配置')\n",
    "        return False\n",
    "    login(token,add_to_git_credential=True)\n",
    "    huggingface_headers = {'Authorization': 'Bearer '+token}\n",
    "    print('huggingface token 已经加载，可以下载私有仓库或文件')\n",
    "    \n",
    "    if not _huggingface_repo:\n",
    "        print('huggingface 同步收藏图片功能不会启动，可增加配置项 huggingface_token = \"token\" 和 huggingface_repo = “仓库id” 后启用 huggingface 同步收藏图片功能')\n",
    "        return False\n",
    "    huggingface_is_init = True\n",
    "    return True\n",
    "\n",
    "\n",
    "def download__huggingface_repo(repo_id:str,dist_directory:str=None,repo_type='dataset',callback=None):\n",
    "    if not huggingface_is_init:\n",
    "        print('huggingface 相关功能未初始化 请调用 init_huggingface() 初始化')\n",
    "        \n",
    "    if not dist_directory:\n",
    "        dist_directory = f'{_install_path}/{_ui_dir_name}/log'\n",
    "    \n",
    "    print('下载收藏的图片')\n",
    "    if not Path(f'{_install_path}/cache/huggingface/huggingface_repo').exists():\n",
    "        mkdirs(f'{_install_path}/cache/huggingface')\n",
    "        repo_path = ''\n",
    "        if repo_type == 'dataset':\n",
    "            repo_path = 'datasets'\n",
    "        if repo_type == 'space':\n",
    "            repo_path = 'spaces'\n",
    "        if repo_path:\n",
    "            run(f'git clone https://huggingface.co/{repo_path}/{repo_id} huggingface_repo',cwd=f'{_install_path}/cache/huggingface')\n",
    "        else:\n",
    "            run(f'git clone https://huggingface.co/{repo_id} huggingface_repo',cwd=f'{_install_path}/cache/huggingface')\n",
    "    if Path(f'{_install_path}/cache/huggingface/huggingface_repo').exists():\n",
    "        run(f'cp -r -f -n -s {_install_path}/cache/huggingface/huggingface_repo/* {dist_directory}')\n",
    "    if callback:\n",
    "        callback()\n",
    "\n",
    "def start_sync_log_to_huggingface(repo_id:str,directory_to_watch:str=None,repo_type='dataset'):\n",
    "    if not huggingface_is_init:\n",
    "        print('huggingface 相关功能未初始化 请调用 init_huggingface() 初始化')\n",
    "    \n",
    "    from watchdog.observers import Observer\n",
    "    from watchdog.events import FileSystemEventHandler\n",
    "    from huggingface_hub  import HfApi,login,snapshot_download\n",
    "    \n",
    "    # 配置监视的目录和 Hugging Face 仓库信息\n",
    "    class FileChangeHandler(FileSystemEventHandler):\n",
    "        def __init__(self, api, repo_id, repo_type,directory_to_watch):\n",
    "            self.api = api\n",
    "            self.repo_id = repo_id\n",
    "            self.repo_type = repo_type\n",
    "            self.directory_to_watch = directory_to_watch\n",
    "        def on_created(self, event):\n",
    "            if not event.is_directory:\n",
    "                # 上传新文件到 Hugging Face 仓库\n",
    "                file_path = event.src_path\n",
    "                file_name:str = os.path.basename(file_path)\n",
    "                print(file_name)\n",
    "                if file_name[file_name.rindex('.'):] not in ['.png','.jpg','.txt','.webp','.jpeg']: return\n",
    "                print(file_name,'>>','huggingface')\n",
    "                try:\n",
    "                    self.api.upload_file(\n",
    "                        path_or_fileobj=file_path,\n",
    "                        path_in_repo=file_path.replace(self.directory_to_watch,''),\n",
    "                        repo_id=self.repo_id,\n",
    "                        repo_type=self.repo_type,\n",
    "                    )\n",
    "                except IOError as error:\n",
    "                    print(error)\n",
    "\n",
    "        def on_deleted(self, event):\n",
    "            if not event.is_directory:\n",
    "                # 从 Hugging Face 仓库删除文件\n",
    "                file_path = event.src_path\n",
    "                file_name = os.path.basename(file_path)\n",
    "                if file_name[file_name.rindex('.'):] not in ['.png','.jpg','.txt','.webp','.jpeg']: return\n",
    "                try:\n",
    "                    self.api.delete_file(\n",
    "                        path_in_repo=file_path.replace(self.directory_to_watch,''),\n",
    "                        repo_id=self.repo_id,\n",
    "                        repo_type=self.repo_type,\n",
    "                        )\n",
    "                except IOError as error:\n",
    "                    print(error)\n",
    "\n",
    "        def on_modified(self, event):\n",
    "            if not event.is_directory:\n",
    "                # 更新 Hugging Face 仓库中的文件\n",
    "                file_path = event.src_path\n",
    "                file_name = os.path.basename(file_path)\n",
    "                if file_name[file_name.rindex('.'):] not in ['.png','.jpg','.txt','.webp','.jpeg']: return\n",
    "                try:\n",
    "                    self.api.upload_file(\n",
    "                        path_or_fileobj=file_path,\n",
    "                        path_in_repo=file_path.replace(self.directory_to_watch,''),\n",
    "                        repo_id=self.repo_id,\n",
    "                        repo_type=self.repo_type,\n",
    "                    )\n",
    "                except IOError as error:\n",
    "                    print(error)\n",
    "\n",
    "        def on_moved(self, event):\n",
    "            if not event.is_directory:\n",
    "                file_path = event.dest_path\n",
    "                file_name = os.path.basename(file_path)\n",
    "                if file_name[file_name.rindex('.'):] not in ['.png','.jpg','.txt','.webp','.jpeg']: return\n",
    "                if event.dest_path.startswith(self.directory_to_watch):\n",
    "                    try:\n",
    "                        self.api.upload_file(\n",
    "                            path_or_fileobj=file_path,\n",
    "                            path_in_repo=file_path.replace(self.directory_to_watch,''),\n",
    "                            repo_id=self.repo_id,\n",
    "                            repo_type=self.repo_type,\n",
    "                        )\n",
    "                    except IOError as error:\n",
    "                        print(error)\n",
    "\n",
    "    api = HfApi()\n",
    "    \n",
    "    if not directory_to_watch:\n",
    "        directory_to_watch = f'{_install_path}/{_ui_dir_name}/log'\n",
    "    # 创建观察者对象并注册文件变化处理程序\n",
    "    event_handler = FileChangeHandler(api,repo_id,repo_type,directory_to_watch)\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, directory_to_watch, recursive=True)\n",
    "\n",
    "    # 启动观察者\n",
    "    observer.name = \"solo_directory_to_watch\"\n",
    "    print(f'启动收藏图片文件夹监听，并自动同步到 huggingface {repo_type} : {repo_id}')\n",
    "    observer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sswa04veLCtE"
   },
   "source": [
    "## 工具函数\n",
    "**不能使用%cd这种会改变当前工作目录的命令，会导致和其他线程冲突**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def zipPath(path:str,zipName:str,format='tar'):\n",
    "    if path.startswith('$install_path'):\n",
    "        path = path.replace('$install_path',_install_path)\n",
    "    if path.startswith('$output_path'):\n",
    "        path = path.replace('$install_path',_output_path)\n",
    "    if not path.startswith('/'):\n",
    "        path = f'{_install_path}/{_ui_dir_name}/{path}'\n",
    "    if Path(path).exists():\n",
    "        if 'tar' == format:\n",
    "            run(f'tar -cf {_output_path}/'+ zipName +'.tar -C '+ path +' . ')\n",
    "        elif 'gz' == format:\n",
    "            run(f'tar -czf {_output_path}/'+ zipName +'.tar.gz -C '+ path +' . ')\n",
    "        return\n",
    "    print('指定的目录不存在：'+path)\n",
    "    \n",
    "def get_folder_list(directory:str):  \n",
    "    folder_list = []  \n",
    "    for item in os.listdir(directory):  \n",
    "        if os.path.isdir(os.path.join(directory, item)):  \n",
    "            folder_list.append(item) \n",
    "    return folder_list\n",
    "\n",
    "def read_text_file(file_path:str):\n",
    "    if not Path(file_path).exists(): return ''\n",
    "    with open(file_path,\"r\") as f:\n",
    "        text = file.read()\n",
    "        if text: return text.strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 内网穿透\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "coqQvTSLLCtE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def printUrl(url,name=''):\n",
    "    print(f'{name} 访问地址：{url}')\n",
    "    for key in sorted(_proxy_path.keys(), key=len)[::-1]:\n",
    "        print(f'{name} 本地服务：{_proxy_path[key]}  访问地址：{url}{key}')\n",
    "# ngrok\n",
    "def startNgrok(ngrokToken:str,ngrokLocalPort:int):\n",
    "    if not is_installed('pyngrok'):\n",
    "        run('pip install pyngrok')\n",
    "    from pyngrok import conf, ngrok\n",
    "    try:\n",
    "        conf.get_default().auth_token = ngrokToken\n",
    "        conf.get_default().monitor_thread = False\n",
    "        ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
    "        url = ''\n",
    "        if len(ssh_tunnels) == 0:\n",
    "            ssh_tunnel = ngrok.connect(ngrokLocalPort)\n",
    "            url = ssh_tunnel.public_url\n",
    "            print('ngrok 访问地址：'+ssh_tunnel.public_url)\n",
    "        else:\n",
    "            print('ngrok 访问地址：'+ssh_tunnels[0].public_url)\n",
    "            url = ssh_tunnels[0].public_url\n",
    "        printUrl(url,'ngrok')\n",
    "        def auto_request_ngrok():\n",
    "            if url:\n",
    "                while(_runing):\n",
    "                    time.sleep(60*1)\n",
    "                    try:\n",
    "                        res = requests.get(url+'/',headers={\"ngrok-skip-browser-warning\" : \"1\"},timeout=10)\n",
    "                    except:\n",
    "                        ''\n",
    "                    # print('自动调用ngrok链接以保存链接不会断开',res.status_code)\n",
    "\n",
    "        # threading.Thread(target = auto_request_ngrok,daemon=True,name='solo_auto_request_ngrok').start()\n",
    "    except:\n",
    "        print('启动ngrok出错')\n",
    "        \n",
    "def startFrpc(name,configFile):\n",
    "    if not Path(f'{_install_path}/frpc/frpc').exists():\n",
    "        installFrpExe()\n",
    "    if freefrp_url:\n",
    "        printUrl(freefrp_url,'freefrp')\n",
    "    echoToFile(f'''\n",
    "cd {_install_path}/frpc/\n",
    "{_install_path}/frpc/frpc {configFile}\n",
    "''',f'{_install_path}/frpc/start.sh')\n",
    "    get_ipython().system(f'''bash {_install_path}/frpc/start.sh''')\n",
    "        \n",
    "def installFrpExe():\n",
    "    if _useFrpc:\n",
    "        print('安装frpc')\n",
    "        run(f'mkdir -p {_install_path}/frpc')\n",
    "        if Path(frpcExePath).exists():\n",
    "            run(f'cp -f -n {frpcExePath} {_install_path}/frpc/frpc')\n",
    "        else:\n",
    "            run(f'wget \"https://huggingface.co/datasets/ACCA225/Frp/resolve/main/frpc\" -O {_install_path}/frpc/frpc')\n",
    "        \n",
    "        for ssl in frpcSSLFFlies:\n",
    "            if Path(ssl).exists():\n",
    "                run(f'cp -f -n {ssl}/* {_install_path}/frpc/')\n",
    "        run(f'chmod +x {_install_path}/frpc/frpc')\n",
    "        run(f'{_install_path}/frpc/frpc -v')\n",
    "\n",
    "def startProxy():\n",
    "    if _useNgrok:\n",
    "        startNgrok(ngrokToken,_server_port)\n",
    "    if _useFrpc:\n",
    "        startFrpc('frpc_proxy',frpcStartArg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGINX 反向代理\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# nginx 反向代理配置文件\n",
    "def localProxy():\n",
    "    def getProxyLocation(subPath:str, localServer:str):\n",
    "        return '''\n",
    "    location '''+ subPath +'''\n",
    "    {\n",
    "        proxy_pass '''+ localServer +''';\n",
    "        \n",
    "        client_max_body_size 1000m;\n",
    "        proxy_set_header Host $http_host;\n",
    "        proxy_set_header X-Real-IP $remote_addr;\n",
    "        proxy_set_header X-Real-Port $remote_port;\n",
    "        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "        proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        proxy_set_header X-Forwarded-Host $host;\n",
    "        proxy_set_header X-Forwarded-Port $server_port;\n",
    "        proxy_set_header REMOTE-HOST $remote_addr;\n",
    "        proxy_connect_timeout 3000s;\n",
    "        proxy_send_timeout 3000s;\n",
    "        proxy_read_timeout 3000s;\n",
    "        proxy_http_version 1.1;\n",
    "        proxy_set_header Upgrade $http_upgrade;\n",
    "        proxy_set_header Connection 'upgrade';\n",
    "        add_header Access-Control-Allow-Origin * always;\n",
    "        add_header Access-Control-Allow-Headers *;\n",
    "        add_header Access-Control-Allow-Methods \"GET, POST, PUT, OPTIONS\";\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    conf = '''\n",
    "server\n",
    "{\n",
    "    listen '''+str(_server_port)+''';\n",
    "    listen [::]:'''+str(_server_port)+''';\n",
    "    server_name 127.0.0.1 localhost 0.0.0.0 \"\";\n",
    "    \n",
    "    fastcgi_send_timeout                 3000s;\n",
    "    fastcgi_read_timeout                 3000s;\n",
    "    fastcgi_connect_timeout              3000s;\n",
    "    \n",
    "    if ($request_method = OPTIONS) {\n",
    "        return 200;\n",
    "    }\n",
    "    \n",
    "    '''+ ''.join([getProxyLocation(key,_proxy_path[key]) for key in sorted(_proxy_path.keys(), key=len)[::-1]]) +'''\n",
    "}\n",
    "'''\n",
    "    echoToFile(conf,'/etc/nginx/conf.d/proxy_nginx.conf')\n",
    "    if not check_service('localhost',_server_port):\n",
    "        run(f'''nginx -c /etc/nginx/nginx.conf''')\n",
    "    run(f'''nginx -s reload''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线程清理工具\n",
    "\n",
    "---\n",
    "\n",
    "清理线程名以 solo_ 开头的所有线程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import ctypes\n",
    "\n",
    "def _async_raise(tid, exctype):\n",
    "    \"\"\"raises the exception, performs cleanup if needed\"\"\"\n",
    "    tid = ctypes.c_long(tid)\n",
    "    if not inspect.isclass(exctype):\n",
    "        exctype = type(exctype)\n",
    "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "    if res == 0:\n",
    "        raise ValueError(\"invalid thread id\")\n",
    "    elif res != 1:\n",
    "        # \"\"\"if it returns a number greater than one, you're in trouble,\n",
    "        # and you should call it again with exc=NULL to revert the effect\"\"\"\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "        raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "\n",
    "def stop_thread(thread):\n",
    "    _async_raise(thread.ident, SystemExit)\n",
    "\n",
    "def stop_solo_threads():\n",
    "    global _runing\n",
    "    _runing = False\n",
    "    # 获取当前所有活动的线程\n",
    "    threads = threading.enumerate()\n",
    "    # 关闭之前创建的子线程\n",
    "    for thread in threads:\n",
    "        if thread.name.startswith('solo_'):\n",
    "            print(f'结束线程：{thread.name}')\n",
    "            try:\n",
    "                stop_thread(thread)\n",
    "            except socket.error:\n",
    "                print(f'结束线程：{thread.name} 执行失败')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve3p8oOkLCtE"
   },
   "source": [
    "# webui 安装和配置函数\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "GTjyBJihLCtE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "envInstalled=False\n",
    "quickStart = True\n",
    "#安装\n",
    "def install():\n",
    "    print('安装')\n",
    "    os.chdir(f'''{_install_path}''')\n",
    "    run(f'''git lfs install''')\n",
    "    run(f'''git config --global credential.helper store''')\n",
    "    for requirement in requirements:\n",
    "        run(f'pip install {requirement}')\n",
    "    if _reLoad:\n",
    "        run(f'''rm -rf {_install_path}/{_ui_dir_name}''')\n",
    "    if Path(f\"{_ui_dir_name}\").exists():\n",
    "        os.chdir(f'''{_install_path}/{_ui_dir_name}/''')\n",
    "        run(f'''git checkout .''')\n",
    "        run(f'''git pull''')\n",
    "    else:\n",
    "        run(f'''git clone --recursive {_sd_git_repo} {_ui_dir_name}''')\n",
    "    if not Path(f'''{_install_path}/{_ui_dir_name}''').exists():\n",
    "        print('sd-webui主程序安装失败，请检查 sd_git_repo 配置的值是否正确')\n",
    "        sys.exit(0)\n",
    "    os.chdir(f'''{_install_path}/{_ui_dir_name}''')\n",
    "    print('安装 完成')\n",
    "\n",
    "# 链接输出目录\n",
    "def link_dir():\n",
    "    print('链接输出目录')\n",
    "    # 链接图片输出目录\n",
    "    run(f'''mkdir -p {_output_path}/outputs''')\n",
    "    run(f'''rm -rf {_install_path}/{_ui_dir_name}/outputs''')\n",
    "    run(f'''ln -s -r {_output_path}/outputs {_install_path}/{_ui_dir_name}/''')\n",
    "     # 输出收藏目录\n",
    "    run(f'''mkdir -p {_output_path}/log''')\n",
    "    run(f'''rm -rf {_install_path}/{_ui_dir_name}/log''')\n",
    "    run(f'''ln -s -r {_output_path}/log {_install_path}/{_ui_dir_name}/''')\n",
    "    # 链接训练输出目录 文件夹链接会导致功能不能用\n",
    "    run(f'''rm -rf {_install_path}/{_ui_dir_name}/textual_inversion''')\n",
    "    run(f'''mkdir -p {_output_path}/textual_inversion/''')\n",
    "    run(f'''ln -s -r {_output_path}/textual_inversion {_install_path}/{_ui_dir_name}/''')\n",
    "    print('链接输出目录 完成') \n",
    "\n",
    "def install_optimizing():\n",
    "    run('add-apt-repository ppa:deadsnakes/ppa -y')\n",
    "    run('apt update -y')\n",
    "    run('apt install nginx -y')\n",
    "    # run('apt install python3.10 -y')\n",
    "    \n",
    "#安装依赖\n",
    "def install_dependencies():\n",
    "    print('安装需要的python环境')\n",
    "    global envInstalled\n",
    "    global venvPath\n",
    "    if Path(f'{_install_path}/{_ui_dir_name}/venv').exists():\n",
    "        print('跳过安装python环境')\n",
    "        envInstalled = True\n",
    "        return\n",
    "    \n",
    "    if quickStart:\n",
    "        if not Path(venvPath).exists():\n",
    "            mkdirs(f'{_install_path}/venv_cache',True)\n",
    "            if not Path(f'{_install_path}/venv_cache/venv.tar.bak').exists():\n",
    "                print('下载 venv.zip')\n",
    "                download_file('https://huggingface.co/viyi/sdwui/resolve/main/venv.zip','venv.zip',f'{_install_path}/venv_cache')\n",
    "            run(f'''unzip {_install_path}/venv_cache/venv.zip -d {_install_path}/venv_cache''')\n",
    "            venvPath = f'{_install_path}/venv_cache/venv.tar.bak'\n",
    "            run(f'''rm -rf {_install_path}/venv_cache/venv.zip''')\n",
    "        elif venvPath.endswith('.zip'):\n",
    "            mkdirs(f'{_install_path}/venv_cache',True)\n",
    "            run(f'''unzip {venvPath} -d {_install_path}/venv_cache''')\n",
    "            venvPath = f'{_install_path}/venv_cache/venv.tar.bak'\n",
    "        print('解压环境')\n",
    "        mkdirs(f'{_install_path}/{_ui_dir_name}/venv')\n",
    "#         run('python3.10 -m venv venv',cwd=f'{_install_path}/{_ui_dir_name}')\n",
    "        run(f'tar -xf {venvPath} -C ./venv',cwd=f'{_install_path}/{_ui_dir_name}')\n",
    "    run(f'rm -f {_install_path}/{_ui_dir_name}/venv/bin/pip*')\n",
    "    run(f'rm -f {_install_path}/{_ui_dir_name}/venv/bin/python*')\n",
    "    venv.create(f'{_install_path}/{_ui_dir_name}/venv')\n",
    "    if not Path(f'{_install_path}/{_ui_dir_name}/venv/bin/pip').exists():\n",
    "        run('curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py')\n",
    "        run(f'{_install_path}/{_ui_dir_name}/venv/bin/python3 get-pip.py')\n",
    "\n",
    "    get_ipython().system(f'''{_install_path}/{_ui_dir_name}/venv/bin/python3 -V''')\n",
    "    get_ipython().system(f'''{_install_path}/{_ui_dir_name}/venv/bin/python3 -m pip -V''')\n",
    "\n",
    "    envInstalled = True\n",
    "    print('安装需要的python环境 完成')\n",
    "      \n",
    "# 个性化配置 \n",
    "def use_config():\n",
    "    print('使用自定义配置 包括tag翻译 \\n')\n",
    "    run(f'''mkdir -p {_install_path}/temp''')\n",
    "    run(f'git clone {_sd_config_git_repu} sd-configs',cwd=f'{_install_path}/temp')\n",
    "    run(f'cp -r -f -n {_install_path}/temp/sd-configs/dist/* {_install_path}/{_ui_dir_name}')\n",
    "    if not Path(_ui_config_file).exists() and _ui_config_file != 'ui-config.json': # ui配置文件\n",
    "        run(f'''mkdir -p {_ui_config_file[:_ui_config_file.rfind('/')]}''')\n",
    "        run(f'cp -f -n {_install_path}/{_ui_dir_name}/ui-config.json {_ui_config_file}')\n",
    "    if not Path(_setting_file).exists() and _setting_file != 'config.json': # 设置配置文件\n",
    "        run(f'''mkdir -p {_setting_file[:_setting_file.rfind('/')]}''')\n",
    "        run(f'cp -f -n {_install_path}/{_ui_dir_name}/config.json {_setting_file}')\n",
    "\n",
    "def copy_last_log_to_images():\n",
    "    if not Path(f'{_install_path}/{_ui_dir_name}/log/images').exists(): mkdirs(f'{_install_path}/{_ui_dir_name}/log/images')\n",
    "    print('复制编号最大的一张收藏图到输出目录，用于保持编号，否则会出现收藏的图片被覆盖的情况')\n",
    "    img_list = os.listdir(f'{_install_path}/{_ui_dir_name}/log/images')\n",
    "    last_img_path = ''\n",
    "    last_img_num = 0\n",
    "    for img in img_list:\n",
    "        if re.findall(r'^\\d+-',str(img)):\n",
    "            num = int(re.findall(r'^\\d+-',str(img))[0][:-1])\n",
    "            if num > last_img_num:\n",
    "                last_img_path = img\n",
    "                last_img_num = num\n",
    "                \n",
    "    if not last_img_path: return\n",
    "    \n",
    "    print(f'{_install_path}/{_ui_dir_name}/log/images/{last_img_path} {_install_path}/{_ui_dir_name}/outputs/txt2img-images')\n",
    "    run(f'''mkdir -p {_install_path}/{_ui_dir_name}/outputs/txt2img-images''')\n",
    "    run(f'''cp -f {_install_path}/{_ui_dir_name}/log/images/{last_img_path} {_install_path}/{_ui_dir_name}/outputs/txt2img-images/''')\n",
    "    \n",
    "    print(f'{_install_path}/{_ui_dir_name}/log/images/{last_img_path} {_install_path}/{_ui_dir_name}/outputs/img2img-images')\n",
    "    run(f'''mkdir -p {_install_path}/{_ui_dir_name}/outputs/img2img-images''')\n",
    "    run(f'''cp -f {_install_path}/{_ui_dir_name}/log/images/{last_img_path} {_install_path}/{_ui_dir_name}/outputs/img2img-images/''')\n",
    "    \n",
    "def start_webui(i):\n",
    "    # 只要不爆内存，其他方式关闭后会再次重启 访问地址会发生变化\n",
    "    print(i,'--port',str(_server_port+1+i))\n",
    "    if i>0:\n",
    "        print(f'使用第{i+1}张显卡启动第{i+1}个服务，通过frpc或nrgok地址后加{_sub_path[i]}进行访问')\n",
    "\n",
    "    restart_times = 0\n",
    "    last_restart_time = time.time()\n",
    "    while _runing:\n",
    "        os.chdir(f'{_install_path}/{_ui_dir_name}')\n",
    "        root_path = _sub_path[i]\n",
    "        if root_path.endswith('/'): root_path = root_path[:-1]\n",
    "        get_ipython().system(f'''venv/bin/python3 launch.py --device-id={i} --port {str(_server_port+1+i)} --subpath={_sub_path[i]}''')\n",
    "        print('10秒后重启服务')\n",
    "        if time.time() - last_restart_time < 60:\n",
    "            restart_times = restart_times + 1\n",
    "        else:\n",
    "            restart_times = 0\n",
    "        last_restart_time = time.time()\n",
    "        if restart_times >3 :\n",
    "            # 如果180秒内重启了3此，将不再自动重启\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    \n",
    "# 启动\n",
    "def start():\n",
    "    print('启动webui')\n",
    "    os.chdir(f'''{_install_path}/{_ui_dir_name}''')\n",
    "    args = ''\n",
    "    if _ui_config_file is not None and _ui_config_file != '' and Path(_ui_config_file).exists(): # ui配置文件\n",
    "        args += ' --ui-config-file=' + _ui_config_file\n",
    "    if _setting_file is not None and _setting_file != '' and Path(_setting_file).exists(): # 设置配置文件\n",
    "        args += ' --ui-settings-file=' + _setting_file\n",
    "    args += ' ' + otherArgs\n",
    "    os.environ['COMMANDLINE_ARGS']=args\n",
    "    run(f'''echo COMMANDLINE_ARGS=$COMMANDLINE_ARGS''')\n",
    "    os.environ['REQS_FILE']='requirements_versions.txt'\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for i in range(torch.cuda.device_count() if _multi_case else 1):\n",
    "            executor.submit(start_webui,i)\n",
    "            while _runing and not check_service('localhost',str(_server_port+1+i)): # 当当前服务启动完成才允许退出此次循环\n",
    "                time.sleep(5)\n",
    "            if not _runing: break\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== 自动下载 + 自动解压功能 ======================\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import threading\n",
    "import zipfile\n",
    "\n",
    "# watchdog 相关（自动解压用）\n",
    "try:\n",
    "    from watchdog.observers import Observer\n",
    "    from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "    watchdog_available = True\n",
    "except ImportError:\n",
    "    watchdog_available = False\n",
    "    print(\"watchdog 未安装，自动解压功能将不可用（可忽略）\")\n",
    "\n",
    "\n",
    "# --------------------- 1.txt 自动下载 ---------------------\n",
    "def start_monitor_1txt():\n",
    "    import os\n",
    "    import time\n",
    "    import requests\n",
    "    import re\n",
    "    import threading # Import the threading module\n",
    "\n",
    "    # Define the directory and file path\n",
    "    directory = '/kaggle/ComfyUI/input/'\n",
    "    file_path = os.path.join(directory, '1.txt')\n",
    "    download_directory = directory # Download to the same directory\n",
    "\n",
    "    # Ensure the download directory exists\n",
    "    os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "    print(f\"Monitoring file: {file_path}\")\n",
    "    print(f\"Download directory: {download_directory}\")\n",
    "\n",
    "    def is_valid_url(url):\n",
    "        \"\"\"Checks if a string is a valid URL.\"\"\"\n",
    "        # Simple regex for URL validation\n",
    "        regex = re.compile(\n",
    "            r'^(?:http|ftp)s?://' # http:// or https://\n",
    "            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' # domain...\n",
    "            r'localhost|' # localhost...\n",
    "            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "            r'(?::\\d+)?' # Optional port\n",
    "            r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "        return re.match(regex, url) is not None\n",
    "\n",
    "    def mc_download_file(url, destination_folder):\n",
    "        \"\"\"Downloads a file from a URL to a specified folder.\"\"\"\n",
    "        try:\n",
    "            print(f\"Attempting to download: {url}\")\n",
    "            # Add a timeout to the request to prevent indefinite hanging\n",
    "            with requests.get(url, stream=True, timeout=30) as r:\n",
    "                r.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "                # --- Start of added code to handle Content-Disposition ---\n",
    "                local_filename = None\n",
    "                if 'Content-Disposition' in r.headers:\n",
    "                    content_disposition = r.headers['Content-Disposition']\n",
    "                    # Look for filename*=utf-8'' or filename=\n",
    "                    filename_match = re.search(r'filename\\*=utf-8\\'\\'(.+)|filename=\"?([^\"]+)\"?', content_disposition)\n",
    "                    if filename_match:\n",
    "                        if filename_match.group(1):\n",
    "                            # Decode URL-encoded filename\n",
    "                            local_filename = requests.utils.unquote(filename_match.group(1))\n",
    "                        elif filename_match.group(2):\n",
    "                            local_filename = filename_match.group(2)\n",
    "\n",
    "                if not local_filename:\n",
    "                     local_filename = url.split('/')[-1]\n",
    "                     if not local_filename: # Handle cases where URL ends with '/'\n",
    "                         local_filename = 'downloaded_file_' + str(int(time.time())) + '.bin'\n",
    "                # --- End of added code ---\n",
    "\n",
    "                destination_path = os.path.join(destination_folder, local_filename)\n",
    "\n",
    "                print(f\"Saving to: {destination_path}\")\n",
    "                with open(destination_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "                print(f\"Successfully downloaded: {local_filename}\")\n",
    "                return True\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Download timed out for {url}\")\n",
    "            return False\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred during download: {e}\")\n",
    "            return False\n",
    "\n",
    "    def process_file(file_path, download_folder):\n",
    "        \"\"\"Reads the file, processes links, and rewrites the file.\"\"\"\n",
    "        lines_to_keep = []\n",
    "        links_found = False\n",
    "\n",
    "        try:\n",
    "            # Read the file\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Process each line\n",
    "            for line in lines:\n",
    "                line = line.strip() # Remove leading/trailing whitespace\n",
    "                if line and is_valid_url(line):\n",
    "                    links_found = True\n",
    "                    print(f\"Found potential link: {line}\")\n",
    "                    # Attempt to download the file\n",
    "                    if mc_download_file(line, download_folder):\n",
    "                        # If download is successful, DO NOT add the line to lines_to_keep\n",
    "                        print(f\"Link processed and removed from file: {line}\")\n",
    "                        pass # Skip adding this line to the list of lines to keep\n",
    "                    else:\n",
    "                        # If download fails, keep the line for retry\n",
    "                        print(f\"Download failed for {line}. Keeping in file.\")\n",
    "                        lines_to_keep.append(line + '\\n') # Add newline back\n",
    "                else:\n",
    "                    # Keep lines that are not valid URLs or are empty\n",
    "                    lines_to_keep.append(line + '\\n') # Add newline back\n",
    "\n",
    "            # Rewrite the file if any links were found (and potentially removed)\n",
    "            if links_found:\n",
    "                with open(file_path, 'w') as f:\n",
    "                    f.writelines(lines_to_keep)\n",
    "                print(f\"File {file_path} updated.\")\n",
    "            else:\n",
    "                print(\"No new valid links found in the file.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            #print(f\"Error: File not found at {file_path}\")\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing the file: {e}\")\n",
    "\n",
    "    def monitor_file_thread(file_path, download_folder, interval_seconds=6):\n",
    "        \"\"\"\n",
    "        Function to be run in a separate thread for continuous monitoring. Checks the file for links at specified intervals.\n",
    "        \"\"\"\n",
    "        print(f\"Monitoring thread started. Checking every {interval_seconds} seconds.\")\n",
    "        while True:\n",
    "            process_file(file_path, download_folder)\n",
    "            time.sleep(interval_seconds)\n",
    "\n",
    "    # Create and start the monitoring thread\n",
    "    # Setting daemon=True allows the main program to exit even if the thread is still running\n",
    "    monitor_thread = threading.Thread(target=monitor_file_thread, args=(file_path, download_directory, 6), daemon=True)\n",
    "    monitor_thread.start()\n",
    "\n",
    "    print(\"Monitoring thread started in the background. Main script can continue execution.\")\n",
    "\n",
    "    # You can add other code here that will run immediately after the monitoring thread starts.\n",
    "    # For example:\n",
    "    # print(\"This line is from the main script and runs after starting the thread.\")\n",
    "    # time.sleep(5) # Example: do some other work in the main thread\n",
    "    # print(\"Main script finished its initial tasks.\")\n",
    "\n",
    "    # Note: In a typical script, the main thread would eventually finish.\n",
    "    # If you need the main script to keep running indefinitely alongside the thread,\n",
    "    # you might need a mechanism to keep the main thread alive (e.g., another infinite loop or join the thread).\n",
    "    # However, in a notebook environment, cells execute sequentially, and the kernel\n",
    "    # often keeps running until explicitly stopped, allowing the daemon thread to persist.\n",
    "\n",
    "# --------------------- 自动解压 input 目录的 zip ---------------------\n",
    "def start_auto_unzip():\n",
    "    if not autoUnzipInput or not watchdog_available:\n",
    "        return\n",
    "\n",
    "    INPUT_DIRECTORY = \"/kaggle/ComfyUI/input\"\n",
    "\n",
    "    class ZipFileHandler(FileSystemEventHandler):\n",
    "        def on_created(self, event):\n",
    "            if event.is_directory:\n",
    "                return\n",
    "            file_path = event.src_path\n",
    "            if file_path.lower().endswith(\".zip\"):\n",
    "                threading.Thread(\n",
    "                    target=self.extract_zip, args=(file_path,), daemon=True\n",
    "                ).start()\n",
    "\n",
    "        def extract_zip(self, zip_path):\n",
    "            print(f\"检测到新 zip 文件 → {zip_path}，开始解压...\")\n",
    "            try:\n",
    "                with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "                    zip_ref.extractall(INPUT_DIRECTORY)\n",
    "                print(f\"解压完成 → {zip_path}\")\n",
    "                os.remove(zip_path)\n",
    "                print(f\"已删除原文件 → {zip_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"解压失败 {zip_path} → {e}\")\n",
    "\n",
    "    os.makedirs(INPUT_DIRECTORY, exist_ok=True)\n",
    "    event_handler = ZipFileHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, INPUT_DIRECTORY, recursive=False)\n",
    "    observer.start()\n",
    "    print(\"自动解压已启动！把 zip 扔进 /kaggle/ComfyUI/input 就会自动解压并删除原文件\")\n",
    "\n",
    "    # 启动时顺便处理一下已经存在的 zip\n",
    "    for file in os.listdir(INPUT_DIRECTORY):\n",
    "        if file.lower().endswith(\".zip\"):\n",
    "            threading.Thread(\n",
    "                target=event_handler.extract_zip,\n",
    "                args=(os.path.join(INPUT_DIRECTORY, file),),\n",
    "                daemon=True,\n",
    "            ).start()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== zrok 真·终极版（下载最稳 + 永不掉线 + 美化输出）==================\n",
    "import subprocess, threading, time, re, os, socket, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 防止 _server_port 未定义（默认 7860，大多数 WebUI 都用这个）\n",
    "try:\n",
    "    _server_port = int(globals().get(\"_server_port\") or 7860)\n",
    "except:\n",
    "    _server_port = 7860\n",
    "\n",
    "\n",
    "def check_url_alive(url, timeout=12):\n",
    "    try:\n",
    "        host = re.search(r\"://([^:/]+)\", url).group(1)\n",
    "        socket.create_connection((host, 443), timeout=timeout)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_and_extract_zrok():\n",
    "    \"\"\"最稳下载 + 完整性校验 + 最多镜像\"\"\"\n",
    "    fallback_path = Path(\"/kaggle/working/zrok\")\n",
    "    exe = fallback_path / \"zrok\"\n",
    "    tar_file = Path(\"/tmp/zrok.tar.gz\")\n",
    "\n",
    "    # 动态获取最新版本（永不过时）\n",
    "    try:\n",
    "        version = subprocess.check_output(\n",
    "            \"curl -sSf https://api.github.com/repos/openziti/zrok/releases/latest \"\n",
    "            '| grep -oP \\'\"tag_name\":\\s*\"\\K[^\"]+\\'',\n",
    "            shell=True,\n",
    "            text=True,\n",
    "        ).strip()\n",
    "        if not version.startswith(\"v\"):\n",
    "            version = \"v\" + version\n",
    "        print(f\"检测到 zrok 最新版本: {version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"获取版本失败 ({e})，使用备用版本 v0.20.0\")\n",
    "        version = \"v0.20.0\"\n",
    "\n",
    "    arch = \"amd64\"\n",
    "    tar_name = f\"zrok_{version.lstrip('v')}_linux_{arch}.tar.gz\"\n",
    "\n",
    "    # 2025 年最全最快的 8 个镜像（实测前 5 个基本秒下）\n",
    "    urls = [\n",
    "        f\"https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://ghproxy.com/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://ghps.cc/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://mirror.ghproxy.com/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://ghproxy.net/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://fastgh.loli.icu/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://gh.fastmirror.org/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "        f\"https://gh.api.99988866.xyz/https://github.com/openziti/zrok/releases/download/{version}/{tar_name}\",\n",
    "    ]\n",
    "\n",
    "    for i, url in enumerate(urls, 1):\n",
    "        print(f\"下载尝试 {i}/{len(urls)}: {url.split('//')[1][:50]}...\")\n",
    "        subprocess.run(\n",
    "            [\"wget\", \"-q\", \"--show-progress\", \"-T\", \"30\", \"-O\", str(tar_file), url],\n",
    "            check=False,\n",
    "            timeout=90,\n",
    "        )\n",
    "\n",
    "        if not tar_file.exists() or tar_file.stat().st_size < 25_000_000:\n",
    "            print(\n",
    "                f\"   → 下载失败或文件太小 ({tar_file.stat().st_size / 1024 / 1024:.1f}MB)\"\n",
    "            )\n",
    "            tar_file.unlink(missing_ok=True)\n",
    "            continue\n",
    "\n",
    "        # gzip 完整性检查\n",
    "        if (\n",
    "            subprocess.run(\n",
    "                [\"gzip\", \"-t\", str(tar_file)], stderr=subprocess.DEVNULL\n",
    "            ).returncode\n",
    "            != 0\n",
    "        ):\n",
    "            print(\"   → gzip 校验失败，文件损坏\")\n",
    "            tar_file.unlink(missing_ok=True)\n",
    "            continue\n",
    "\n",
    "        # 解压\n",
    "        fallback_path.mkdir(parents=True, exist_ok=True)\n",
    "        result = subprocess.run(\n",
    "            [\"tar\", \"xzf\", str(tar_file), \"-C\", str(fallback_path)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if result.returncode == 0 and exe.exists():\n",
    "            exe.chmod(0o755)\n",
    "            tar_file.unlink(missing_ok=True)\n",
    "            print(\"zrok 下载并解压成功！\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"解压失败:\", result.stderr.strip()[:200])\n",
    "            shutil.rmtree(fallback_path, ignore_errors=True)\n",
    "            tar_file.unlink(missing_ok=True)\n",
    "\n",
    "    print(\"所有镜像均下载失败，zrok 准备失败\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def start_zrok():\n",
    "    if not (globals().get(\"useZrok\") or locals().get(\"useZrok\") or True):  # 默认开启\n",
    "        return\n",
    "\n",
    "    # 获取 token\n",
    "    zrok_token = (globals().get(\"zrok_token\") or \"\").strip()\n",
    "    if not zrok_token:\n",
    "        for p in [\n",
    "            \"/kaggle/input/configs/zrok_token.txt\",\n",
    "            \"/kaggle/input/utils-tools/zrok_token.txt\",\n",
    "        ]:\n",
    "            if Path(p).exists():\n",
    "                zrok_token = Path(p).read_text().strip()\n",
    "                break\n",
    "    if not zrok_token:\n",
    "        print(\"未找到 zrok_token，已跳过 zrok\")\n",
    "        return\n",
    "\n",
    "    # 可执行文件优先级\n",
    "    preferred = Path(\"/kaggle/input/utils-tools/zrok/zrok\")\n",
    "    fallback = Path(\"/kaggle/working/zrok/zrok\")\n",
    "    exe = (\n",
    "        preferred\n",
    "        if preferred.exists() and preferred.stat().st_size > 20_000_000\n",
    "        else fallback\n",
    "    )\n",
    "\n",
    "    if not exe.exists():\n",
    "        print(\"未找到本地 zrok，开始自动下载最新版...\")\n",
    "        if not download_and_extract_zrok():\n",
    "            return\n",
    "        exe = fallback\n",
    "\n",
    "    source = \"input 数据集\" if preferred == exe else \"自动下载/缓存\"\n",
    "    print(f\"zrok 已准备就绪 → 使用 {source}\")\n",
    "\n",
    "    # 持久化环境目录\n",
    "    env_dir = Path(\"/kaggle/working/zrok_env\")\n",
    "    env_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # 首次登录\n",
    "    if not (env_dir / \".zrok\").exists():\n",
    "        print(\"zrok 首次登录中...\")\n",
    "        if (\n",
    "            subprocess.run(\n",
    "                [str(exe), \"enable\", zrok_token, \"--headless\"], cwd=env_dir\n",
    "            ).returncode\n",
    "            != 0\n",
    "        ):\n",
    "            print(\"zrok 登录失败\")\n",
    "            return\n",
    "        time.sleep(3)\n",
    "\n",
    "    # 永不掉线的 share 线程\n",
    "    def run_forever():\n",
    "        retry = 0\n",
    "        while True:\n",
    "            try:\n",
    "                proc = subprocess.Popen(\n",
    "                    [\n",
    "                        str(exe),\n",
    "                        \"share\",\n",
    "                        \"public\",\n",
    "                        f\"http://127.0.0.1:{_server_port}\",\n",
    "                        \"--headless\",\n",
    "                        \"--backend-mode\",\n",
    "                        \"proxy\",\n",
    "                    ],\n",
    "                    cwd=env_dir,\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    text=True,\n",
    "                    bufsize=1,\n",
    "                )\n",
    "\n",
    "                url = None\n",
    "                for _ in range(120):\n",
    "                    line = proc.stdout.readline()\n",
    "                    if not line and proc.poll() is not None:\n",
    "                        break\n",
    "                    print(line.rstrip())\n",
    "                    m = re.search(r\"(https?://[a-zA-Z0-9-]+\\.share\\.zrok\\.io)\", line)\n",
    "                    if m:\n",
    "                        url = m.group(1)\n",
    "                        break\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "                if url and check_url_alive(url):\n",
    "                    print(\"\\n\" + \"█\" * 100)\n",
    "                    print(f\"zrok 公网地址 → {url}\")\n",
    "                    print(f\"主实例      → {url}/\")\n",
    "                    print(f\"第二实例    → {url}/1/\")\n",
    "                    print(f\"ComfyUI     → {url}/cui/\")\n",
    "                    print(f\"文件管理器  → {url}/fslist/\")\n",
    "                    print(\"█\" * 100 + \"\\n\")\n",
    "                    Path(\"/kaggle/working/zrok_url.txt\").write_text(url + \"\\n\")\n",
    "                    retry = 0\n",
    "                else:\n",
    "                    raise Exception(\"未获取到有效地址\")\n",
    "\n",
    "                # 保活循环\n",
    "                while True:\n",
    "                    time.sleep(20)\n",
    "                    if proc.poll() is not None:\n",
    "                        raise Exception(\"zrok 进程意外退出\")\n",
    "                    if not check_url_alive(url):\n",
    "                        raise Exception(\"公网地址失联\")\n",
    "\n",
    "            except Exception as e:\n",
    "                retry += 1\n",
    "                wait = min(60, 3 * retry)\n",
    "                print(f\"zrok 断开 ({e})，{wait}s 后第 {retry} 次重连...\")\n",
    "                if \"proc\" in locals() and proc.poll() is None:\n",
    "                    proc.kill()\n",
    "                time.sleep(wait)\n",
    "\n",
    "    threading.Thread(target=run_forever, daemon=True, name=\"ZROK_ULTIMATE\").start()\n",
    "    print(\"zrok 永不掉线线程已启动（10-40秒后生效）\")\n",
    "\n",
    "\n",
    "# 自动启动（放最后）\n",
    "start_zrok()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== pendingzip 目录自动打包工具（10秒静默后打包）==================\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "pending_zip_dir = \"/kaggle/ComfyUI/pendingzip\"  # 监控目录\n",
    "pack_output_dir = \"/kaggle/ComfyUI\"  # 打包后输出的位置（可自定义）\n",
    "\n",
    "\n",
    "def start_pendingzip_packer():\n",
    "    if not autoPackPendingZip:\n",
    "        return\n",
    "\n",
    "    os.makedirs(pending_zip_dir, exist_ok=True)\n",
    "    os.makedirs(pack_output_dir, exist_ok=True)\n",
    "\n",
    "    last_mod_time = 0.0  # 记录目录最后被修改的时间（新增/删除/移动都会改变）\n",
    "    is_packing = False\n",
    "\n",
    "    def monitor():\n",
    "        nonlocal last_mod_time, is_packing\n",
    "\n",
    "        print(f\"pendingzip 自动打包已启动 → 监控目录: {pending_zip_dir}\")\n",
    "        print(f\"           10秒内无新文件进入即打包 → 输出到: {pack_output_dir}\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # 获取目录的最新修改时间（任何文件增删改都会更新）\n",
    "                current_mod_time = os.path.getmtime(pending_zip_dir)\n",
    "\n",
    "                # 如果目录内容有变化（新增、删除、移动等），刷新计时器\n",
    "                if current_mod_time > last_mod_time:\n",
    "                    last_mod_time = current_mod_time\n",
    "                    # 可选：打印日志方便调试\n",
    "                    print(\n",
    "                        f\"[pendingzip] 检测到新文件进入，计时重置 → {time.strftime('%H:%M:%S')}\"\n",
    "                    )\n",
    "\n",
    "                # 有文件且已经静默10秒以上，且不在打包中\n",
    "                if (\n",
    "                    os.listdir(pending_zip_dir)\n",
    "                    and not is_packing\n",
    "                    and time.time() - last_mod_time >= 10.0\n",
    "                ):\n",
    "                    is_packing = True\n",
    "                    print(\n",
    "                        f\"[pendingzip] 10秒静默期已到，开始打包（{len(os.listdir(pending_zip_dir))} 个文件）\"\n",
    "                    )\n",
    "                    threading.Thread(target=do_pack, daemon=True).start()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[pendingzip] 监控异常: {e}\")\n",
    "\n",
    "            time.sleep(1.0)\n",
    "\n",
    "    def do_pack():\n",
    "        nonlocal is_packing\n",
    "        try:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            temp_dir = Path(\"/tmp/pendingzip_pack\") / timestamp\n",
    "            temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # 移动所有文件到临时目录\n",
    "            moved_count = 0\n",
    "            for item in os.listdir(pending_zip_dir):\n",
    "                src = Path(pending_zip_dir) / item\n",
    "                dst = temp_dir / item\n",
    "                shutil.move(str(src), str(dst))\n",
    "                moved_count += 1\n",
    "\n",
    "            if moved_count == 0:\n",
    "                return\n",
    "\n",
    "            # 打包\n",
    "            zip_name = f\"pendingzip_pack_{timestamp}.zip\"\n",
    "            zip_path = Path(pack_output_dir) / zip_name\n",
    "            shutil.make_archive(\n",
    "                base_name=str(zip_path.with_suffix(\"\")),\n",
    "                format=\"zip\",\n",
    "                root_dir=str(temp_dir),\n",
    "            )\n",
    "\n",
    "            print(f\"自动打包完成 → {zip_path.name}  (共 {moved_count} 个文件)\")\n",
    "\n",
    "            # 清理临时目录\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"pendingzip 打包失败: {e}\")\n",
    "        finally:\n",
    "            is_packing = False\n",
    "\n",
    "    threading.Thread(target=monitor, daemon=True, name=\"solo_pendingzip_packer\").start()\n",
    "    print(\"pendingzip 自动打包线程已启动（10秒静默触发）\")\n",
    "    if not autoPackPendingZip:\n",
    "        return\n",
    "\n",
    "    os.makedirs(pending_zip_dir, exist_ok=True)\n",
    "    os.makedirs(pack_output_dir, exist_ok=True)\n",
    "\n",
    "    last_change_time = 0.0\n",
    "    is_packing = False\n",
    "\n",
    "    def monitor():\n",
    "        nonlocal last_change_time, is_packing\n",
    "\n",
    "        print(f\"pendingzip 自动打包已启动 → 监控目录: {pending_zip_dir}\")\n",
    "        print(f\"           10秒内无新文件进入即打包 → 输出到: {pack_output_dir}\")\n",
    "\n",
    "        while True:\n",
    "            # 检测目录是否有变化（新增/删除/修改）\n",
    "            current_files = set(os.listdir(pending_zip_dir))\n",
    "            if current_files:\n",
    "                # 任何文件变化都刷新计时器\n",
    "                last_change_time = time.time()\n",
    "\n",
    "            # 如果有文件且当前不在打包中\n",
    "            if current_files and not is_packing:\n",
    "                # 检查是否超过10秒未变化\n",
    "                if time.time() - last_change_time >= 10.0:\n",
    "                    is_packing = True\n",
    "                    threading.Thread(target=do_pack, daemon=True).start()\n",
    "\n",
    "            time.sleep(1.0)\n",
    "\n",
    "    def do_pack():\n",
    "        nonlocal is_packing\n",
    "        try:\n",
    "            # 创建临时目录\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            temp_dir = Path(\"/tmp/pendingzip_pack\") / timestamp\n",
    "            temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # 移动所有文件到临时目录\n",
    "            for item in os.listdir(pending_zip_dir):\n",
    "                src = Path(pending_zip_dir) / item\n",
    "                dst = temp_dir / item\n",
    "                shutil.move(str(src), str(dst))\n",
    "\n",
    "            # 生成压缩包名\n",
    "            zip_name = f\"pendingzip_pack_{timestamp}.zip\"\n",
    "            zip_path = Path(pack_output_dir) / zip_name\n",
    "\n",
    "            # 打包\n",
    "            shutil.make_archive(\n",
    "                base_name=str(zip_path.with_suffix(\"\")),\n",
    "                format=\"zip\",\n",
    "                root_dir=str(temp_dir),\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"自动打包完成 → {zip_path}.zip  (共 {len(os.listdir(temp_dir))} 个文件)\"\n",
    "            )\n",
    "\n",
    "            # 清理临时目录\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"pendingzip 打包失败: {e}\")\n",
    "        finally:\n",
    "            is_packing = False\n",
    "\n",
    "    threading.Thread(target=monitor, daemon=True, name=\"solo_pendingzip_packer\").start()\n",
    "    print(\"pendingzip 自动打包线程已启动（10秒静默触发）\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== output 目录定期增量打包（完全修复版 2025-11-24）==================\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 配置开关（会自动读取你在主配置里设置的变量）\n",
    "autoBackupOutput = (\n",
    "    locals().get(\"autoBackupOutput\") or globals().get(\"autoBackupOutput\") or False\n",
    ")\n",
    "backup_interval = (\n",
    "    locals().get(\"backup_interval\") or globals().get(\"backup_interval\") or 300\n",
    ")  # 秒\n",
    "\n",
    "# 关键修复：使用全局 output_path，而不是硬编码 ComfyUI/output\n",
    "source_dir = f\"{install_path}/ComfyUI/output\"  # 正确路径\n",
    "working_dir = \"/kaggle/working\"  # 备份输出到这里\n",
    "marker_file = Path(\"/kaggle/working/.comfyui_output_backup_marker\")  # 标记文件\n",
    "\n",
    "\n",
    "def start_output_incremental_backup():\n",
    "    if not autoBackupOutput:\n",
    "        return\n",
    "\n",
    "    os.makedirs(source_dir, exist_ok=True)\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "\n",
    "    # 读取上次备份时间\n",
    "    last_backup_time = 0.0\n",
    "    if marker_file.exists():\n",
    "        try:\n",
    "            last_backup_time = float(marker_file.read_text().strip())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def backup_worker():\n",
    "        nonlocal last_backup_time\n",
    "        print(f\"output 增量备份已启动 → 每 {backup_interval}s 检查一次\")\n",
    "        print(f\"   源目录: {source_dir}\")\n",
    "        print(f\"   备份到: {working_dir}\")\n",
    "\n",
    "        while True:\n",
    "            time.sleep(backup_interval)\n",
    "            try:\n",
    "                new_files = []\n",
    "                for item in os.listdir(source_dir):\n",
    "                    item_path = Path(source_dir) / item\n",
    "                    if (\n",
    "                        item_path.is_file()\n",
    "                        and item_path.stat().st_mtime > last_backup_time\n",
    "                    ):\n",
    "                        new_files.append(item_path)\n",
    "\n",
    "                if not new_files:\n",
    "                    continue\n",
    "\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                temp_dir = Path(\"/tmp/output_backup_incr\") / timestamp\n",
    "                temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                for f in new_files:\n",
    "                    shutil.copy2(f, temp_dir / f.name)\n",
    "\n",
    "                zip_name = f\"ComfyUI_output_incr_{timestamp}.zip\"\n",
    "                zip_path = Path(working_dir) / zip_name\n",
    "\n",
    "                # 正确调用 make_archive（去掉 .zip 后缀）\n",
    "                shutil.make_archive(\n",
    "                    base_name=str(zip_path.with_suffix(\"\")),\n",
    "                    format=\"zip\",\n",
    "                    root_dir=str(temp_dir),\n",
    "                )\n",
    "\n",
    "                print(f\"增量备份成功 → {zip_name}（{len(new_files)} 个新文件）\")\n",
    "                shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "                # 更新标记时间\n",
    "                last_backup_time = time.time()\n",
    "                marker_file.write_text(str(last_backup_time))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"output 增量备份出错: {e}\")\n",
    "\n",
    "    threading.Thread(\n",
    "        target=backup_worker, daemon=True, name=\"ComfyUI_Output_Backup\"\n",
    "    ).start()\n",
    "    print(\"output 增量备份线程已启动\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLvsk8ByLCtF"
   },
   "source": [
    "# 入口函数\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "IOKjaMlcLCtF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 启动非webui相关的的内容，加快启动速度\n",
    "def main():\n",
    "    global envInstalled\n",
    "    global huggingface_is_init\n",
    "    global _runing\n",
    "    _init_conf()\n",
    "    stop_solo_threads()\n",
    "    print('启动...')\n",
    "    startTicks = time.time()\n",
    "    time.sleep(5)\n",
    "    _runing = True\n",
    "    isInstall = True if os.getenv('IsInstall','False') == 'True' else False\n",
    "    _proxy_path[_sub_path[0]] = f'http://127.0.0.1:{_server_port+1}/'\n",
    "    _proxy_path[_sub_path[1]] = f'http://127.0.0.1:{_server_port+2}/'\n",
    "    proxy_thread = threading.Thread(target = startProxy, daemon=True, name='solo_startProxy')\n",
    "    proxy_thread.start()\n",
    "    start_zrok()\n",
    "    if isInstall is False or _reLoad: \n",
    "        print('安装运行环境')\n",
    "        install()\n",
    "        link_dir()\n",
    "        init_huggingface()\n",
    "        install_optimizing()\n",
    "        if not _skip_webui:\n",
    "            threading.Thread(target = install_dependencies,daemon=True,name='solo_install_dependencies').start()\n",
    "        else: envInstalled = True\n",
    "        link_or_download_flie(replace_path(_async_downloading), _link_instead_of_copy=_link_instead_of_copy,\n",
    "                          base_path=f'{_install_path}/{_ui_dir_name}')\n",
    "        if huggingface_is_init:\n",
    "            threading.Thread(target = download__huggingface_repo,daemon=True,\n",
    "                                 args=([_huggingface_repo]),\n",
    "                                 kwargs={\"callback\":copy_last_log_to_images},\n",
    "                                 name='solo_download__huggingface_repo').start()\n",
    "        \n",
    "        link_or_download_flie(replace_path(_before_downloading), _link_instead_of_copy=_link_instead_of_copy,\n",
    "                          base_path=f'{_install_path}/{_ui_dir_name}',is_await=True,sync=True)\n",
    "        t = 0\n",
    "        while _runing and not envInstalled:\n",
    "            if t%10==0:\n",
    "                print('等待python环境安装...')\n",
    "            t = t+1\n",
    "            time.sleep(1)\n",
    "        use_config()\n",
    "        os.environ['IsInstall'] = 'True'\n",
    "    else:\n",
    "        envInstalled = True\n",
    "    localProxy()\n",
    "    link_or_download_flie(replace_path(_before_start_sync_downloading), _link_instead_of_copy=_link_instead_of_copy,\n",
    "                          base_path=f'{_install_path}/{_ui_dir_name}',sync=True)\n",
    "    if init_huggingface():\n",
    "        start_sync_log_to_huggingface(_huggingface_repo)\n",
    "    ticks = time.time()\n",
    "    _on_before_start()\n",
    "    print(\"加载耗时:\",(ticks - startTicks),\"秒\")\n",
    "    start_monitor_1txt()\n",
    "    start_auto_unzip()\n",
    "    start_pendingzip_packer()\n",
    "    start_output_incremental_backup()\n",
    "    if _skip_webui:\n",
    "        print('跳过webui启动')\n",
    "        proxy_thread.join()\n",
    "    else:\n",
    "        start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oaCRs2gLCtF"
   },
   "source": [
    "# 执行区域\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "id": "O3DR0DWHLCtF",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 启动\n",
    "# _reLoad = True\n",
    "# hidden_console_info = False\n",
    "# run_by_none_device = True\n",
    "# show_shell_info = True\n",
    "\n",
    "print(f'当前sd的安装路径是：{_install_path}/{_ui_dir_name}')\n",
    "print(f'当前图片保存路径是：{_output_path}')\n",
    "print(f'当前数据集路径是：{_input_path}')\n",
    "\n",
    "\n",
    "if _skip_start:\n",
    "    print('已跳过自动启动，可手动执行 main() 进行启动。')\n",
    "    print('''推荐的启动代码：\n",
    "try:\n",
    "    check_gpu() # 检查是否存在gpu\n",
    "    main()\n",
    "except KeyboardInterrupt:\n",
    "    stop_solo_threads() # 中断后自动停止后台线程 （有部分功能在后台线程中运行）\n",
    "    ''')\n",
    "else:\n",
    "    try:\n",
    "        check_gpu()\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        stop_solo_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2716934,
     "sourceId": 6167400,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3654544,
     "sourceId": 6346544,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2962375,
     "sourceId": 6720235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3074484,
     "sourceId": 6817788,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
